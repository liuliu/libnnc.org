

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>NNC Static Schedule A Graph &mdash; nnc, a deep learning framework from ccv</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex/" />
    <link rel="search" title="Search" href="../../search/" />
    <link rel="next" title="NNC Dynamic Graph Execution" href="../nnc-dy/" />
    <link rel="prev" title="The NNC Tensor Allocation Algorithm" href="../nnc-alloc/" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../">
          

          
            
            <img src="../../_static/nnc-logo.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                a deep learning framework from ccv
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../overview/">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../overview/#what-s-nnc">What’s NNC?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../overview/#tensors-commands-and-streams">1. Tensors, Commands and Streams</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../overview/#computation-graph">2. Computation Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../overview/#symbolic-graph">3. Symbolic Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../overview/#dynamic-graph">4. Dynamic Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../overview/#common-neural-network-primitives">5. Common Neural Network Primitives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../overview/#supplementary-materials">Supplementary Materials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../overview/#toll-free-bridging">Toll-Free Bridging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../overview/#automatic-differentiation">Automatic Differentiation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../overview/#while-type-sub-graph"><code class="docutils literal notranslate"><span class="pre">while</span></code> Type Sub-Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../overview/#case-of-type-sub-graph"><code class="docutils literal notranslate"><span class="pre">case..of</span></code> Type Sub-Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../overview/#limits-and-constraints">Limits and Constraints</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../">Technicals</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../nnc-alloc/">The NNC Tensor Allocation Algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnc-alloc/#tensor-representation">Tensor Representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-alloc/#loop-representation">Loop Representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-alloc/#the-problem-definition">The Problem Definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-alloc/#the-core-algorithm">The Core Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-alloc/#basic-structure">Basic Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-alloc/#candidate-selection">Candidate Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-alloc/#insertion">Insertion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-alloc/#intuition">Intuition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-alloc/#loop">Loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-alloc/#multi-view-tensor">Multi-view Tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-alloc/#loop-with-efficient-tensor-allocation">Loop with Efficient Tensor Allocation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-alloc/#sub-computation-graph">Sub-Computation Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-alloc/#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">NNC Static Schedule A Graph</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#stream">Stream</a></li>
<li class="toctree-l3"><a class="reference internal" href="#static-schedule">Static Schedule</a></li>
<li class="toctree-l3"><a class="reference internal" href="#while-and-case-of"><code class="docutils literal notranslate"><span class="pre">while</span></code> and <code class="docutils literal notranslate"><span class="pre">case..of</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../nnc-dy/">NNC Dynamic Graph Execution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnc-dy/#naming-the-variable">Naming The Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-dy/#tracing-the-operation">Tracing The Operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-dy/#optimizations">Optimizations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-dy/#interoperability-not-ready">Interoperability (Not Ready)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-dy/#future-optimizations">Future Optimizations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-dy/#some-maybes">Some Maybes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../nnc-cnnp/">NNC Common Neural Network Primitives</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnc-cnnp/#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-cnnp/#model-io">Model IO</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../nnc-df/">NNC Dataframe</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnc-df/#operations-on-the-data">Operations on the Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-df/#iteration">Iteration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-df/#map">Map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-df/#reduce">Reduce</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnc-df/#others">Others</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api/">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api/level-0/">Level 0 API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-0/#essentials">Essentials</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api/level-1/">Level 1 API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-1/#tensors">Tensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-1/#commands">Commands</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-1/#streams">Streams</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api/level-2/">Level 2 API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-2/#essentials">Essentials</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-2/#others">Others</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api/level-3/">Level 3 API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-3/#essentials">Essentials</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-3/#others">Others</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api/level-3.5/">Level 3.5 API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api/level_3_5/group__level__3__5__case__of_symbolic_switch/">Construct “switch” control structure in symbolic graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level_3_5/group__level__3__5__simplify_symbolic_simplify/">Symbolic graph simplification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level_3_5/group__level__3__5__while_symbolic_while/">Construct a “while” loop in a symbolic graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-3.5/#automatic-differentiation">Automatic Differentiation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-3.5/#while-loop-essentials">While Loop Essentials</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-3.5/#branching">Branching</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-3.5/#gradient-based-optimization">Gradient-based Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-3.5/#graph-simplification">Graph Simplification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-3.5/#automatic-graph-parallelization">Automatic Graph Parallelization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-3.5/#while-loop-others">While Loop Others</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api/level-4/">Level 4 API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-4/#essentials">Essentials</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api/level-5/">Level 5 API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api/level_5/group__level__5_dataframe/">What is “dataframe” in ML?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level_5/group__level__5_model/">Models, layers, and Keras</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-5/#dataframe-api">Dataframe API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-5/#dataframe-add-ons">Dataframe Add-ons</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/level-5/#model-api">Model API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api/convenience/">Convenience API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/commands/">Available Commands</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api/commands/#backends">Backends</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/commands/#commands">Commands</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/commands/#command-identifiers">Command Identifiers</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          
            <a href="../../">
          

          
            
            <img src="../../_static/nnc-logo.svg" class="logo" alt="Logo"/>
          
          </a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../">Docs</a> &raquo;</li>
        
          <li><a href="../">Technicals</a> &raquo;</li>
        
      <li>NNC Static Schedule A Graph</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/tech/nnc-schd.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="nnc-static-schedule-a-graph">
<h1>NNC Static Schedule A Graph<a class="headerlink" href="#nnc-static-schedule-a-graph" title="Permalink to this headline">¶</a></h1>
<p>A concrete graph runs in topological order sequentially when you invoke <a class="reference internal" href="../../api/level-2/#_CPPv317ccv_nnc_graph_runPC15ccv_nnc_graph_tPC21ccv_nnc_tensor_tape_tPC24ccv_nnc_stream_context_tKiPCK20ccv_nnc_graph_exec_tKiPCK20ccv_nnc_graph_exec_tKi" title="ccv_nnc_graph_run"><code class="xref cpp cpp-func docutils literal notranslate"><span class="pre">ccv_nnc_graph_run</span></code></a>. Thus, all dependencies executed before the subsequent command got executed. This default behavior doesn’t leverage massive parallelism built in today’s CPU / GPU environment, leaves too much computation power on the table.</p>
<p>NNC supports to static schedule a graph such that all the parallelism are utilized. That’s been said, <strong>static scheduling</strong> shouldn’t be confused with <strong>automatic parallelization</strong>. The later term suggests to turn a non-parallelizable graph into a parallelizable ones by adding additional data transfers or graph transformations. <strong>Static scheduling</strong> considers dependencies of a command, and try to schedule independent commands onto different streams.</p>
<div class="section" id="stream">
<h2>Stream<a class="headerlink" href="#stream" title="Permalink to this headline">¶</a></h2>
<p>One of the core abstraction for the execution model is the <strong>stream</strong>. This models closely to <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM">CUDA stream</a>. Two commands scheduled on the same stream guaranteed to be executed sequentially. Different streams can collaborate with <strong>signals</strong>. The <strong>signal</strong> models closely to <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT">CUDA event</a>, with the same limitation that if a signal is not scheduled on a stream, wait on it will be a no-op.</p>
<p>That all sounds very much like a thin wrapper around CUDA runtime. The key difference is that you can also schedule a graph onto a stream, and they will be executed serially with other graphs scheduled on the same stream.</p>
</div>
<div class="section" id="static-schedule">
<h2>Static Schedule<a class="headerlink" href="#static-schedule" title="Permalink to this headline">¶</a></h2>
<p>Conceptually, the <strong>static scheduling</strong> algorithm for a graph is trivial. A new stream can be spawned whenever there is a split. The new stream can be either recycled from a stream that is terminated or a newly created. However, there are some factors at play. For example, if there are repeated branch-and-merge, you can alternate streams for your execution. Consider <code class="docutils literal notranslate"><span class="pre">N1</span> <span class="pre">-&gt;</span> <span class="pre">(N2,</span> <span class="pre">N3)</span> <span class="pre">-&gt;</span> <span class="pre">N4</span></code>, you can assign <code class="docutils literal notranslate"><span class="pre">N1</span></code>, <code class="docutils literal notranslate"><span class="pre">N2</span></code> to stream 0, and <code class="docutils literal notranslate"><span class="pre">N3</span></code>, <code class="docutils literal notranslate"><span class="pre">N4</span></code> to stream 1. Alternatively, you can assign <code class="docutils literal notranslate"><span class="pre">N1</span></code>, <code class="docutils literal notranslate"><span class="pre">N2</span></code>, <code class="docutils literal notranslate"><span class="pre">N4</span></code> to stream 0 and <code class="docutils literal notranslate"><span class="pre">N3</span></code> to stream 1. Both are equivalent if stream only maintains the execution order. In NNC’s implementation however, stream also maintains execution context and workspace memory for BLAS, CuDNN etc. We prefer the second scheduling.</p>
<p>The <strong>static scheduling</strong> algorithm implemented in NNC went through a few iterations. The current iteration first do a reverse traversal of the graph, assign each node a rank. The rank is the length of the longest chain follows the current node. When traverse the graph, if the current node hasn’t assigned stream yet, we will find a recyclable stream (a stream that is deterministically terminated before the current node), or create a new stream. From the current node, we will find its highest ranked unassigned following node, assign the new stream to it. We use this node as the new node, repeat steps until no unassigned following node can be found. If two nodes have the same rank, we break the tie by checking whether in this given stream, we already encountered the same command before (thus, sharing workspace memory and execution context is possible).</p>
<p>As part of the static scheduling work, a node can be associated with multiple streams. This is useful for commands that need to communicate across devices because each stream can only be associated with one device.</p>
</div>
<div class="section" id="while-and-case-of">
<h2><code class="docutils literal notranslate"><span class="pre">while</span></code> and <code class="docutils literal notranslate"><span class="pre">case..of</span></code><a class="headerlink" href="#while-and-case-of" title="Permalink to this headline">¶</a></h2>
<p>A concrete graph in NNC can contain branches and loops. A naive implemenation such as CUDA streams / events cannot handle these. A lightweight coroutine implementation based on <code class="docutils literal notranslate"><span class="pre">&lt;ucontext.h&gt;</span></code> enables us to implement <code class="docutils literal notranslate"><span class="pre">while</span></code> and <code class="docutils literal notranslate"><span class="pre">case..of</span></code> properly while still leveraging CUDA streams / events construction.</p>
<p>For loops and branches to work, the expressions should be evaluated each loop or before branching to determine whether we continue looping or where to branch to. Some tensor reconfigurations need to happen as well for each loop or after branching. Since streams are asynchronous, it is not obvious how to do it efficiently and correctly with only CUDA streams / events.</p>
<p>We effectively implemented some coroutine helpers such that the current task can yield while waiting for CUDA stream to finish. This is transparent and if other nodes are not blocked by the loop or branching, can still continue be scheduled until everything is blocked by a loop or branching. At that point, we will create a new thread to wait, to maintain the illusion that the interface is asynchronous. The new thread is only for scheduling, and no matter how many streams we allocate, we only have this one thread to schedule.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../nnc-dy/" class="btn btn-neutral float-right" title="NNC Dynamic Graph Execution" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../nnc-alloc/" class="btn btn-neutral" title="The NNC Tensor Allocation Algorithm" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, libnnc.org.
      
        <span class="build">
          <a href="https://github.com/liuliu/ccv">View the project on GitHub</a>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'a deep learning framework from ccv',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  

  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-303081-9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-303081-9');
  </script>

   

</body>
</html>