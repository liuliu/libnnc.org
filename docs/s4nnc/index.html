<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Swift for NNC  Reference</title>
    <link rel="stylesheet" type="text/css" href="css/jazzy.css" />
    <link rel="stylesheet" type="text/css" href="css/highlight.css" />
    <meta charset='utf-8'>
    <script src="js/jquery.min.js" defer></script>
    <script src="js/jazzy.js" defer></script>
    
    <script src="js/lunr.min.js" defer></script>
    <script src="js/typeahead.jquery.js" defer></script>
    <script src="js/jazzy.search.js" defer></script>
  </head>
  <body>
    <a title="Swift for NNC  Reference"></a>
    <header>
      <div class="content-wrapper">
        <p><a href="index.html">Swift for NNC Docs</a> (49% documented)</p>
        <p class="header-right">
          <form role="search" action="search.json">
            <input type="text" placeholder="Search documentation" data-typeahead>
          </form>
        </p>
      </div>
    </header>
    <div class="content-wrapper">
      <p id="breadcrumbs">
        <a href="index.html">Swift for NNC Reference</a>
        <img id="carat" src="img/carat.png" />
        Swift for NNC  Reference
      </p>
    </div>
    <div class="content-wrapper">
      <nav class="sidebar">
        <ul class="nav-groups">
          <li class="nav-group-name">
            <a href="Classes.html">Classes</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Classes/Add.html">Add</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/AnyModelBuilder.html">AnyModelBuilder</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes.html#/s:4main16AnyTensorStorageC">AnyTensorStorage</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/AveragePool.html">AveragePool</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/BatchNorm.html">BatchNorm</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Concat.html">Concat</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Convolution.html">Convolution</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Dense.html">Dense</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Dropout.html">Dropout</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/DynamicGraph.html">DynamicGraph</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/DynamicGraph/AnyTensor.html">– AnyTensor</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/DynamicGraph/Tensor.html">– Tensor</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/DynamicGraph/Group.html">– Group</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/DynamicGraph/LogLevel.html">– LogLevel</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/DynamicGraph/Statistics.html">– Statistics</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/DynamicGraph/Store.html">– Store</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Embedding.html">Embedding</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Flatten.html">Flatten</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/IndexSelect.html">IndexSelect</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Input.html">Input</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/LSTM.html">LSTM</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/LayerNorm.html">LayerNorm</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/MaskedFill.html">MaskedFill</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Matmul.html">Matmul</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Max.html">Max</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/MaxPool.html">MaxPool</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Min.html">Min</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Model.html">Model</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Model/IO.html">– IO</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Model/Parameters.html">– Parameters</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Model/ParametersType.html">– ParametersType</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/ModelBuilder.html">ModelBuilder</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Mul.html">Mul</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/ReLU.html">ReLU</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/ReduceMax.html">ReduceMax</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/ReduceNorm2.html">ReduceNorm2</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/ReduceSum.html">ReduceSum</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Reshape.html">Reshape</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Scalmul.html">Scalmul</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Sigmoid.html">Sigmoid</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Softmax.html">Softmax</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/StreamContext.html">StreamContext</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Sum.html">Sum</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Swish.html">Swish</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Tanh.html">Tanh</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Transpose.html">Transpose</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Enums.html">Enumerations</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Enums/DataType.html">DataType</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/DeviceKind.html">DeviceKind</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/DeviceKind/GPUs.html">– GPUs</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/Functional.html">Functional</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/ImageJitter.html">ImageJitter</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/ImageJitter/Size.html">– Size</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/ImageJitter/Resize.html">– Resize</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/ImageJitter/Offset.html">– Offset</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/ImageJitter/Normalize.html">– Normalize</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/ReduceOp.html">ReduceOp</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/TensorDimensionFormat.html">TensorDimensionFormat</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/TensorFormat.html">TensorFormat</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Extensions.html">Extensions</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Extensions/Collection.html">Collection</a>
              </li>
              <li class="nav-group-task">
                <a href="Extensions/Float16.html">Float16</a>
              </li>
              <li class="nav-group-task">
                <a href="Extensions/Float32.html">Float32</a>
              </li>
              <li class="nav-group-task">
                <a href="Extensions/Float64.html">Float64</a>
              </li>
              <li class="nav-group-task">
                <a href="Extensions/Int32.html">Int32</a>
              </li>
              <li class="nav-group-task">
                <a href="Extensions/Int64.html">Int64</a>
              </li>
              <li class="nav-group-task">
                <a href="Extensions/UInt8.html">UInt8</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Functions.html">Functions</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main1moiyAA5ModelC2IOCAF_AFtF">*(_:_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main1moiyAA5ModelC2IOCAF_SftF">*(_:_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main1moiyAA5ModelC2IOCSf_AFtF">*(_:_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main1moiyxSf_xtAA24DynamicGraph_TensorGroupRzlF">*(_:_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main1moiyxx_SftAA24DynamicGraph_TensorGroupRzlF">*(_:_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main1moiyxx_xtAA24DynamicGraph_TensorGroupRzlF">*(_:_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main1poiyAA5ModelC2IOCAF_AFtF">+(_:_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main1poiyxx_xtAA24DynamicGraph_TensorGroupRzlF">+(_:_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main1sopyAA5ModelC2IOCAFF">-(_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main1sopyxxAA24DynamicGraph_TensorGroupRzlF">-(_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main1soiyAA5ModelC2IOCAF_AFtF">-(_:_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main1soiyxx_xtAA24DynamicGraph_TensorGroupRzlF">-(_:_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main2zmoiyAA5ModelC2IOCAF_AFtF">.*(_:_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main2zmoiyxx_xtAA24DynamicGraph_TensorGroupRzlF">.*(_:_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main2zpoiyAA5ModelC2IOCAF_AFtF">.+(_:_:)</a>
              </li>
              <li class="nav-group-task">
                <a href="Functions.html#/s:4main2zpoiyxx_xtAA24DynamicGraph_TensorGroupRzlF">.+(_:_:)</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Protocols.html">Protocols</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Protocols/AnyTensor.html">AnyTensor</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/DataSeries.html">DataSeries</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/DynamicGraph_Any.html">DynamicGraph_Any</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/DynamicGraph_AnyGroup.html">DynamicGraph_AnyGroup</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols.html#/s:4main26DynamicGraph_AnyParametersP">DynamicGraph_AnyParameters</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/DynamicGraph_AnyTensor.html">DynamicGraph_AnyTensor</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/DynamicGraph_AnyTensorGroup.html">DynamicGraph_AnyTensorGroup</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/DynamicGraph_TensorGroup.html">DynamicGraph_TensorGroup</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/Loss.html">Loss</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/Optimizer.html">Optimizer</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/TensorNumeric.html">TensorNumeric</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/_DynamicGraph_TensorGroup.html">_DynamicGraph_TensorGroup</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Structs.html">Structures</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Structs/AdamOptimizer.html">AdamOptimizer</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/BinaryCrossEntropyLoss.html">BinaryCrossEntropyLoss</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/CategoricalCrossEntropyLoss.html">CategoricalCrossEntropyLoss</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/DataFrame.html">DataFrame</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/DataFrame/UntypedSeries.html">– UntypedSeries</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/DataFrame/TypedSeries.html">– TypedSeries</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/DataFrame/ManyUntypedSeries.html">– ManyUntypedSeries</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/DataFrame/ManyUntypedSeriesTensorResult.html">– ManyUntypedSeriesTensorResult</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/DataSeriesIterator.html">DataSeriesIterator</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Hint.html">Hint</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Hint/Border.html">– Border</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/LAMBOptimizer.html">LAMBOptimizer</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/SGDOptimizer.html">SGDOptimizer</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Sequential.html">Sequential</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/SigmoidBinaryCrossEntropyLoss.html">SigmoidBinaryCrossEntropyLoss</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/SmoothL1Loss.html">SmoothL1Loss</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/SoftmaxCrossEntropyLoss.html">SoftmaxCrossEntropyLoss</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Tensor.html">Tensor</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Tensor/NumpyScalarCompatibleError.html">– NumpyScalarCompatibleError</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Typealiases.html">Type Aliases</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Typealiases.html#/s:4main5Groupa">Group</a>
              </li>
            </ul>
          </li>
        </ul>
      </nav>
      <article class="main-content">
        <section>
          <section class="section">
            
            <h1 id='swift-for-nnc' class='heading'>Swift for NNC</h1>

<p><a href="https://github.com/liuliu/s4nnc/actions/workflows/ubuntu-bazel.yaml?query=branch%3Amain"><img src="https://github.com/liuliu/s4nnc/actions/workflows/ubuntu-bazel.yaml/badge.svg?branch=main" alt="ubuntu-bazel"></a></p>

<p>s4nnc is a Swift interface for <a href="https://libnnc.org">libnnc</a> library.</p>

<p>From the very start, <a href="https://libnnc.org">libnnc</a> is meant to be a common runtime that supports many language bindings. It becomes apparent during the development that for deep learning, a raw C interface would be unwieldy complex to use in real-life. For example, the training loop of a transformer model for sentiment analysis takes more than 400 lines of code: <a href="https://github.com/liuliu/ccv/blob/unstable/bin/nnc/imdb.c#L268">https://github.com/liuliu/ccv/blob/unstable/bin/nnc/imdb.c#L268</a></p>

<p>A high-level language that delegates most of the work to the C runtime seems to be a win in brevity and usefulness. The same training loop of a transformer model in Swift takes less than 100 lines: <a href="https://github.com/liuliu/s4nnc/blob/main/examples/imdb/main.swift#L197">https://github.com/liuliu/s4nnc/blob/main/examples/imdb/main.swift#L197</a></p>

<p>Because the heavy-lifting is done in the <a href="https://libnnc.org">libnnc</a> library, the Swift portion can be light and even automatically generated. At the moment, we have about 3,000 lines of Swift code to run quite a few models on GPU, complete with data feeders, model specifications and optimizers.</p>
<h2 id='runtime-api' class='heading'>Runtime API</h2>

<p>Currently, s4nnc works better under Linux with CUDA 11, CuDNN and NCCL. The API for s4nnc wraps around <a href="https://libnnc.org/api/level-4/">Level-4</a> and <a href="https://libnnc.org/api/level-5/">Level-5</a> C APIs.</p>
<h3 id='tensor' class='heading'>Tensor</h3>
<pre class="highlight swift"><code><span class="kd">public</span> <span class="kd">struct</span> <span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Element</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="nf">init</span><span class="p">(</span><span class="n">_</span> <span class="nv">kind</span><span class="p">:</span> <span class="kt">DeviceKind</span><span class="p">,</span> <span class="n">_</span> <span class="nv">dimensionFormat</span><span class="p">:</span> <span class="kt">TensorDimensionFormat</span><span class="p">)</span>
  <span class="kd">init</span><span class="o">&lt;</span><span class="kt">S</span><span class="p">:</span> <span class="kt">Sequence</span><span class="o">&gt;</span><span class="p">(</span><span class="n">_</span> <span class="nv">sequence</span><span class="p">:</span> <span class="kt">S</span><span class="p">,</span> <span class="n">_</span> <span class="nv">kind</span><span class="p">:</span> <span class="kt">DeviceKind</span><span class="p">,</span> <span class="n">_</span> <span class="nv">dimensionFormat</span><span class="p">:</span> <span class="kt">TensorDimensionFormat</span><span class="p">)</span> <span class="k">where</span> <span class="kt">S</span><span class="o">.</span><span class="kt">Element</span> <span class="o">==</span> <span class="kt">Element</span>
<span class="p">}</span>
</code></pre>

<p>This method initialize a raw tensor that resides either on CPU or GPU with a given dimensions. Alternatively, you can initialize a tensor from native Swift array. Basic usage looks like this:</p>
<pre class="highlight swift"><code><span class="k">var</span> <span class="nv">tensor</span> <span class="o">=</span> <span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Float</span><span class="o">&gt;</span><span class="p">(</span><span class="o">.</span><span class="kt">CPU</span><span class="p">,</span> <span class="o">.</span><span class="kt">HWC</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
</code></pre>

<p>There are very limited functionalities associated with raw tensors. Mostly, you can only <code>reshaped</code> or <code>toGPU</code> / <code>toCPU</code>.</p>
<h3 id='dynamicgraph' class='heading'>DynamicGraph</h3>

<p><code><a href="Classes/DynamicGraph.html">DynamicGraph</a></code> is where you associate most computations with tensors. The <code><a href="Classes/DynamicGraph.html">DynamicGraph</a></code> operates on tensor variables / constants, not the raw tensors. Initializing a tensor variable / constant is very similar to initializing a raw tensor:</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">graph</span> <span class="o">=</span> <span class="kt">DynamicGraph</span><span class="p">()</span>
<span class="k">let</span> <span class="nv">variable</span><span class="p">:</span> <span class="kt">DynamicGraph</span><span class="o">.</span><span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Float</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="nf">variable</span><span class="p">(</span><span class="o">.</span><span class="kt">CPU</span><span class="p">,</span> <span class="o">.</span><span class="kt">HWC</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</code></pre>

<p>A tensor variable can participate computations, for example:</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">x</span><span class="p">:</span> <span class="kt">DynamicGraph</span><span class="o">.</span><span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Float</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="nf">variable</span><span class="p">(</span><span class="o">.</span><span class="kt">CPU</span><span class="p">,</span> <span class="o">.</span><span class="kt">C</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="k">let</span> <span class="nv">y</span><span class="p">:</span> <span class="kt">DynamicGraph</span><span class="o">.</span><span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Float</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="nf">variable</span><span class="p">(</span><span class="o">.</span><span class="kt">CPU</span><span class="p">,</span> <span class="o">.</span><span class="kt">C</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="k">let</span> <span class="nv">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">.*</span> <span class="n">y</span>
<span class="nf">print</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre>

<p>Because these are tensor variables, you can also do automatic differentiation:</p>
<pre class="highlight swift"><code><span class="n">x</span><span class="o">.</span><span class="n">requiresGrad</span> <span class="o">=</span> <span class="kc">true</span>
<span class="n">z</span><span class="o">.</span><span class="nf">backward</span><span class="p">(</span><span class="nv">to</span><span class="p">:</span> <span class="p">[</span><span class="n">x</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="kt">DynamicGraph</span><span class="o">.</span><span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">!</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
</code></pre>

<p><code>requiresGrad</code> in above code merely denotes we need to populate the <code>grad</code> property of <code>x</code>. It doesn&rsquo;t carry other significance unlike in PyTorch.</p>

<p>Tensor variables memory management is automatic. If there is no reference to it (as defined by no automatic differentiation requires the given tensor variable&rsquo;s participation), the memory will be freed. Hence, unlike PyTorch, you don&rsquo;t need to worry about <code>no_grad</code> annotation most of the time.</p>
<h3 id='model-and-optimizer' class='heading'>Model and Optimizer</h3>

<p>Computations on <code><a href="Classes/DynamicGraph.html">DynamicGraph</a></code> with tensor variables are stateless. s4nnc also provided stateful <code><a href="Classes/Model.html">Model</a></code> that contains trainable parameters. You can use <code><a href="Classes/Model.html">Model</a></code> to construct complex computation unit and train them.</p>
<pre class="highlight swift"><code><span class="kd">func</span> <span class="kt">TwoLayerLinearModel</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">let</span> <span class="nv">x</span> <span class="o">=</span> <span class="kt">Input</span><span class="p">()</span>
  <span class="k">let</span> <span class="nv">y</span> <span class="o">=</span> <span class="kt">Dense</span><span class="p">(</span><span class="nv">count</span><span class="p">:</span> <span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">let</span> <span class="nv">z</span> <span class="o">=</span> <span class="kt">Dense</span><span class="p">(</span><span class="nv">count</span><span class="p">:</span> <span class="mi">1</span><span class="p">)(</span><span class="n">y</span><span class="p">)</span>
  <span class="k">return</span> <span class="kt">Model</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="p">[</span><span class="n">z</span><span class="p">])</span>
<span class="p">}</span>

<span class="k">let</span> <span class="nv">twoLayerModel</span> <span class="o">=</span> <span class="kt">TwoLayerLinearModel</span><span class="p">()</span>
<span class="k">let</span> <span class="nv">z</span> <span class="o">=</span> <span class="nf">twoLayerModel</span><span class="p">(</span><span class="nv">inputs</span><span class="p">:</span> <span class="n">x</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</code></pre>

<p>You can train the model with optimizers.</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">sgd</span> <span class="o">=</span> <span class="kt">SGDOptimizer</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="nv">nesterov</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span> <span class="nv">rate</span><span class="p">:</span> <span class="mf">0.0001</span><span class="p">,</span> <span class="nv">scale</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="nv">decay</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="nv">momentum</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span> <span class="nv">dampening</span><span class="p">:</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">sgd</span><span class="o">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">twoLayerModel</span><span class="o">.</span><span class="n">parameters</span><span class="p">]</span>
<span class="k">for</span> <span class="n">_</span> <span class="mi">0</span><span class="o">..&lt;</span><span class="mi">100</span> <span class="p">{</span>
  <span class="k">let</span> <span class="nv">x</span><span class="p">:</span> <span class="kt">DynamicGraph</span><span class="o">.</span><span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Float</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="nf">variable</span><span class="p">(</span><span class="o">.</span><span class="kt">CPU</span><span class="p">,</span> <span class="o">.</span><span class="kt">C</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
  <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="k">let</span> <span class="nv">target</span><span class="p">:</span> <span class="kt">DynamicGraph</span><span class="o">.</span><span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Float</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="nf">variable</span><span class="p">(</span><span class="o">.</span><span class="kt">CPU</span><span class="p">,</span> <span class="o">.</span><span class="kt">C</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
  <span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">let</span> <span class="nv">z</span> <span class="o">=</span> <span class="nf">twoLayerModel</span><span class="p">(</span><span class="nv">inputs</span><span class="p">:</span> <span class="n">x</span><span class="p">)</span>
  <span class="k">let</span> <span class="nv">binaryLoss</span> <span class="o">=</span> <span class="kt">SigmoidBinaryCrossEntropyLoss</span><span class="p">()</span>
  <span class="k">let</span> <span class="nv">loss</span> <span class="o">=</span> <span class="nf">binaryLoss</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="nv">target</span><span class="p">:</span> <span class="n">target</span><span class="p">)</span>
  <span class="n">loss</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nf">backward</span><span class="p">(</span><span class="nv">to</span><span class="p">:</span> <span class="p">[</span><span class="n">x</span><span class="p">])</span>
  <span class="n">sgd</span><span class="o">.</span><span class="nf">step</span><span class="p">()</span>
<span class="p">}</span>
</code></pre>

<p>Because <code><a href="Classes/Model.html">Model</a></code> can express complex computations statically, it is recommended to have most of your computations expressed as <code><a href="Classes/Model.html">Model</a></code>.</p>
<h3 id='modelbuilder' class='heading'>ModelBuilder</h3>

<p>Sometimes, your <code><a href="Classes/Model.html">Model</a></code> can change its shape based on the inputs. <code><a href="Classes/ModelBuilder.html">ModelBuilder</a></code> can take the input, and generate appropriate model. However, these models need to match on parameters. For example, if you have different length of text input to your transformer model, <code><a href="Classes/ModelBuilder.html">ModelBuilder</a></code> can be helpful.</p>
<h3 id='dataframe' class='heading'>DataFrame</h3>

<p><code><a href="Structs/DataFrame.html">DataFrame</a></code> provides an easy way to construct data feeder into your computation. The data feeder is memory and computation efficient, meaning for each column you try to pull, only that column will be materialized. Hence, if you loop through a list of file names and declare a column to be the loaded images, only one image loaded at a time when you loop through the <code><a href="Structs/DataFrame.html">DataFrame</a></code>.</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">df</span> <span class="o">=</span> <span class="kt">DataFrame</span><span class="p">(</span><span class="nv">from</span><span class="p">:</span> <span class="p">[</span><span class="n">filename1</span><span class="p">,</span> <span class="n">filename2</span><span class="p">,</span> <span class="n">filename3</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s">"image"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"0"</span><span class="p">]</span><span class="o">!.</span><span class="nf">toLoadImage</span><span class="p">()</span>
<span class="k">for</span> <span class="n">tensor</span> <span class="k">in</span> <span class="n">df</span><span class="p">[</span><span class="s">"image"</span><span class="p">,</span> <span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">UInt8</span><span class="o">&gt;.</span><span class="k">self</span><span class="p">]</span> <span class="p">{</span>
  <span class="nf">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>

<p>We only load one image at a time, and the previous image is freed as soon as the next image pulled in.</p>

<p>The <code><a href="Structs/DataFrame.html">DataFrame</a></code> object also provided basic functionalities to load from a CSV file. The CSV reader is considered to be fastest multi-core reader at the moment.</p>
<h3 id='streamcontext' class='heading'>StreamContext</h3>

<p>Unlike PyTorch, s4nnc doesn&rsquo;t associate with implicit asynchronous stream when execute on GPU. To leverage asynchronous stream to improve computation efficiency, you can associate a <code><a href="Classes/StreamContext.html">StreamContext</a></code> explicitly.</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">computeStream</span> <span class="o">=</span> <span class="kt">StreamContext</span><span class="p">(</span><span class="o">.</span><span class="kt">GPU</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="k">var</span> <span class="nv">z</span><span class="p">:</span> <span class="kt">DynamicGraph</span><span class="o">.</span><span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Float</span><span class="o">&gt;</span><span class="p">?</span> <span class="o">=</span> <span class="kc">nil</span>
<span class="n">graph</span><span class="o">.</span><span class="nf">withStream</span><span class="p">(</span><span class="n">computeStream</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">let</span> <span class="nv">x</span><span class="p">:</span> <span class="kt">DynamicGraph</span><span class="o">.</span><span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Float</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="nf">variable</span><span class="p">(</span><span class="o">.</span><span class="kt">CPU</span><span class="p">,</span> <span class="o">.</span><span class="kt">C</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
  <span class="k">let</span> <span class="nv">y</span><span class="p">:</span> <span class="kt">DynamicGraph</span><span class="o">.</span><span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Float</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="nf">variable</span><span class="p">(</span><span class="o">.</span><span class="kt">CPU</span><span class="p">,</span> <span class="o">.</span><span class="kt">C</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
  <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
  <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">.+</span> <span class="n">y</span>
<span class="p">}</span>
<span class="n">computeStream</span><span class="o">.</span><span class="nf">joined</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1">// Result only available after joined the computeStream</span>
</code></pre>
<h3 id='storing-models-and-tensors' class='heading'>Storing Models and Tensors</h3>

<p>A simple SQLite based data storage is provided from s4nnc. It is a key-value based storage for tensors, tensor variables and models. You can:</p>
<pre class="highlight swift"><code><span class="n">graph</span><span class="o">.</span><span class="nf">openStore</span><span class="p">(</span><span class="s">"filePath"</span><span class="p">)</span> <span class="p">{</span> <span class="n">store</span> <span class="k">in</span>
  <span class="k">let</span> <span class="nv">aTensor</span> <span class="o">=</span> <span class="n">store</span><span class="o">.</span><span class="nf">read</span><span class="p">(</span><span class="s">"a"</span><span class="p">)</span>
  <span class="n">store</span><span class="o">.</span><span class="nf">write</span><span class="p">(</span><span class="s">"b"</span><span class="p">,</span> <span class="nv">variable</span><span class="p">:</span> <span class="n">z</span><span class="p">)</span>
  <span class="n">store</span><span class="o">.</span><span class="nf">write</span><span class="p">(</span><span class="s">"2layer"</span><span class="p">,</span> <span class="nv">model</span><span class="p">:</span> <span class="n">twoLayerModel</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>
<h3 id='group' class='heading'>Group</h3>

<p>Multiple tensor variables can be grouped together for computations.</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">xGroup</span> <span class="o">=</span> <span class="kt">Group</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">)</span>
<span class="k">let</span> <span class="nv">yGroup</span> <span class="o">=</span> <span class="kt">Group</span><span class="p">(</span><span class="n">y0</span><span class="p">,</span> <span class="n">y1</span><span class="p">)</span>
<span class="k">let</span> <span class="nv">zGroup</span> <span class="o">=</span> <span class="n">xGroup</span> <span class="o">.*</span> <span class="n">yGroup</span>
</code></pre>

<p>This is useful because if tensor variables are on different GPUs, this can compute simultaneously. With <code><a href="Classes/Model.html">Model</a></code> and <code><a href="Protocols/Optimizer.html">Optimizer</a></code>, it is a transparent way to apply data parallelism to speed up your training loop.</p>
<h2 id='example' class='heading'>Example</h2>

<p>Below are the training loop to train an sentiment analysis transformer model with s4nnc. It trains the model with multiple GPUs. You can find comparable PyTorch code from <a href="http://peterbloem.nl/blog/transformers">Transformers from Scratch</a>. You can find the rest of the code in <a href="https://github.com/liuliu/s4nnc/blob/main/examples/imdb/main.swift">https://github.com/liuliu/s4nnc/blob/main/examples/imdb/main.swift</a>.</p>
<h3 id='setup-the-data-feeder-pipeline' class='heading'>Setup the Data Feeder Pipeline</h3>
<pre class="highlight swift"><code><span class="k">var</span> <span class="nv">trainData</span> <span class="o">=</span> <span class="nf">dataFromDisk</span><span class="p">(</span><span class="nv">filePath</span><span class="p">:</span> <span class="n">trainListFile</span><span class="p">)</span>
<span class="c1">// Extract tensors from ImdbText struct.</span>
<span class="n">trainData</span><span class="p">[</span><span class="s">"tensor"</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainData</span><span class="p">[</span><span class="s">"main"</span><span class="p">,</span> <span class="kt">ImdbText</span><span class="o">.</span><span class="k">self</span><span class="p">]</span><span class="o">.</span><span class="nf">map</span><span class="p">(\</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span>
<span class="n">trainData</span><span class="p">[</span><span class="s">"mask"</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainData</span><span class="p">[</span><span class="s">"main"</span><span class="p">,</span> <span class="kt">ImdbText</span><span class="o">.</span><span class="k">self</span><span class="p">]</span><span class="o">.</span><span class="nf">map</span><span class="p">(\</span><span class="o">.</span><span class="n">mask</span><span class="p">)</span>
<span class="n">trainData</span><span class="p">[</span><span class="s">"c"</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainData</span><span class="p">[</span><span class="s">"main"</span><span class="p">,</span> <span class="kt">ImdbText</span><span class="o">.</span><span class="k">self</span><span class="p">]</span><span class="o">.</span><span class="nf">map</span><span class="p">(\</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>
<span class="c1">// Create one hot tensor out of the scalar.</span>
<span class="n">trainData</span><span class="p">[</span><span class="s">"oneHot"</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainData</span><span class="p">[</span><span class="s">"c"</span><span class="p">,</span> <span class="kt">Int</span><span class="o">.</span><span class="k">self</span><span class="p">]</span><span class="o">.</span><span class="nf">toOneHot</span><span class="p">(</span><span class="kt">Float32</span><span class="o">.</span><span class="k">self</span><span class="p">,</span> <span class="nv">count</span><span class="p">:</span> <span class="mi">2</span><span class="p">)</span>

<span class="k">let</span> <span class="nv">deviceCount</span> <span class="o">=</span> <span class="kt">DeviceKind</span><span class="o">.</span><span class="kt">GPUs</span><span class="o">.</span><span class="n">count</span>

<span class="c1">// Batching tensors together. </span>
<span class="k">var</span> <span class="nv">batchedTrainData</span> <span class="o">=</span> <span class="n">trainData</span><span class="p">[</span><span class="s">"tensor"</span><span class="p">,</span> <span class="s">"mask"</span><span class="p">,</span> <span class="s">"oneHot"</span><span class="p">]</span><span class="o">.</span><span class="nf">combine</span><span class="p">(</span><span class="nv">size</span><span class="p">:</span> <span class="n">batchSize</span><span class="p">,</span> <span class="nv">repeating</span><span class="p">:</span> <span class="n">deviceCount</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..&lt;</span><span class="n">deviceCount</span> <span class="p">{</span>
  <span class="n">batchedTrainData</span><span class="p">[</span><span class="s">"truncTensor_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchedTrainData</span><span class="p">[</span><span class="s">"tensor_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">]</span><span class="o">!.</span><span class="nf">toTruncate</span><span class="p">(</span><span class="n">batchedTrainData</span><span class="p">[</span><span class="s">"mask_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">]</span><span class="o">!</span><span class="p">)</span>
  <span class="n">batchedTrainData</span><span class="p">[</span><span class="s">"squaredMask_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchedTrainData</span><span class="p">[</span><span class="s">"mask_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">]</span><span class="o">!.</span><span class="nf">toOneSquared</span><span class="p">(</span><span class="nv">maxLength</span><span class="p">:</span> <span class="n">maxLength</span><span class="p">)</span>
  <span class="c1">// Move the tensors from CPU to GPU.</span>
  <span class="k">let</span> <span class="nv">toGPUTrain</span> <span class="o">=</span> <span class="n">batchedTrainData</span><span class="p">[</span><span class="s">"truncTensor_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">,</span> <span class="s">"oneHot_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">,</span> <span class="s">"squaredMask_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">]</span><span class="o">.</span><span class="nf">toGPU</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
  <span class="n">batchedTrainData</span><span class="p">[</span><span class="s">"tensorGPU_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">toGPUTrain</span><span class="p">[</span><span class="s">"truncTensor_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">]</span>
  <span class="n">batchedTrainData</span><span class="p">[</span><span class="s">"oneHotGPU_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">toGPUTrain</span><span class="p">[</span><span class="s">"oneHot_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">]</span>
  <span class="n">batchedTrainData</span><span class="p">[</span><span class="s">"squaredMaskGPU_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">toGPUTrain</span><span class="p">[</span><span class="s">"squaredMask_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">]</span>
<span class="p">}</span>
</code></pre>
<h3 id='the-training-loop' class='heading'>The Training Loop</h3>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">graph</span> <span class="o">=</span> <span class="kt">DynamicGraph</span><span class="p">()</span>

<span class="k">let</span> <span class="nv">vocabVec</span><span class="p">:</span> <span class="kt">Group</span><span class="o">&lt;</span><span class="kt">DynamicGraph</span><span class="o">.</span><span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Float32</span><span class="o">&gt;&gt;</span> <span class="o">=</span> <span class="kt">Group</span><span class="p">((</span><span class="mi">0</span><span class="o">..&lt;</span><span class="n">deviceCount</span><span class="p">)</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">graph</span><span class="o">.</span><span class="nf">variable</span><span class="p">(</span><span class="o">.</span><span class="kt">GPU</span><span class="p">(</span><span class="nv">$0</span><span class="p">),</span> <span class="o">.</span><span class="kt">NC</span><span class="p">(</span><span class="n">vocabSize</span><span class="p">,</span> <span class="n">embeddingSize</span><span class="p">))</span> <span class="p">})</span>
<span class="k">let</span> <span class="nv">seqVec</span><span class="p">:</span> <span class="kt">Group</span><span class="o">&lt;</span><span class="kt">DynamicGraph</span><span class="o">.</span><span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Float32</span><span class="o">&gt;&gt;</span> <span class="o">=</span> <span class="kt">Group</span><span class="p">((</span><span class="mi">0</span><span class="o">..&lt;</span><span class="n">deviceCount</span><span class="p">)</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">graph</span><span class="o">.</span><span class="nf">variable</span><span class="p">(</span><span class="o">.</span><span class="kt">GPU</span><span class="p">(</span><span class="nv">$0</span><span class="p">),</span> <span class="o">.</span><span class="kt">NC</span><span class="p">(</span><span class="n">maxLength</span><span class="p">,</span> <span class="n">embeddingSize</span><span class="p">))</span> <span class="p">})</span>
<span class="n">vocabVec</span><span class="o">.</span><span class="nf">rand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">...</span><span class="mi">1</span><span class="p">)</span>
<span class="n">seqVec</span><span class="o">.</span><span class="nf">rand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">...</span><span class="mi">1</span><span class="p">)</span>
<span class="k">var</span> <span class="nv">adamOptimizer</span> <span class="o">=</span> <span class="kt">AdamOptimizer</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="nv">rate</span><span class="p">:</span> <span class="mf">0.0001</span><span class="p">,</span> <span class="nv">betas</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.98</span><span class="p">),</span> <span class="nv">decay</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="nv">epsilon</span><span class="p">:</span> <span class="mf">1e-9</span><span class="p">)</span>
<span class="n">adamOptimizer</span><span class="o">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocabVec</span><span class="p">,</span> <span class="n">seqVec</span><span class="p">,</span> <span class="n">transformer</span><span class="o">.</span><span class="n">parameters</span><span class="p">]</span>
<span class="k">var</span> <span class="nv">overallAccuracy</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..&lt;</span><span class="mi">10</span> <span class="p">{</span>
  <span class="n">batchedTrainData</span><span class="o">.</span><span class="nf">shuffle</span><span class="p">()</span>
  <span class="k">var</span> <span class="nv">columns</span> <span class="o">=</span> <span class="p">[</span><span class="kt">String</span><span class="p">]()</span>
  <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..&lt;</span><span class="n">deviceCount</span> <span class="p">{</span>
    <span class="n">columns</span> <span class="o">+=</span> <span class="p">[</span><span class="s">"tensorGPU_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">,</span> <span class="s">"oneHotGPU_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">,</span> <span class="s">"squaredMaskGPU_</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">"</span><span class="p">]</span>
  <span class="p">}</span>
  <span class="k">let</span> <span class="nv">computeStream</span> <span class="o">=</span> <span class="kt">StreamContext</span><span class="p">(</span><span class="o">.</span><span class="kt">GPU</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
  <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span> <span class="k">in</span> <span class="n">batchedTrainData</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="nf">enumerated</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">adamOptimizer</span><span class="o">.</span><span class="n">rate</span> <span class="o">=</span> <span class="mf">0.0001</span> <span class="o">*</span> <span class="nf">min</span><span class="p">(</span><span class="kt">Float</span><span class="p">(</span><span class="n">adamOptimizer</span><span class="o">.</span><span class="n">step</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">10000.0</span> <span class="o">/</span> <span class="kt">Float</span><span class="p">(</span><span class="n">batchSize</span><span class="p">)),</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="kt">Float</span><span class="p">(</span><span class="n">deviceCount</span><span class="p">)</span>
    <span class="k">let</span> <span class="nv">tensorGPU</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="o">..&lt;</span><span class="n">deviceCount</span><span class="p">)</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">batch</span><span class="p">[</span><span class="nv">$0</span> <span class="o">*</span> <span class="mi">3</span><span class="p">]</span> <span class="k">as!</span> <span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Int32</span><span class="o">&gt;</span> <span class="p">}</span>
    <span class="k">let</span> <span class="nv">oneHotGPU</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="o">..&lt;</span><span class="n">deviceCount</span><span class="p">)</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">batch</span><span class="p">[</span><span class="nv">$0</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="k">as!</span> <span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Float32</span><span class="o">&gt;</span> <span class="p">}</span>
    <span class="k">let</span> <span class="nv">squaredMaskGPU</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="o">..&lt;</span><span class="n">deviceCount</span><span class="p">)</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">batch</span><span class="p">[</span><span class="nv">$0</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span> <span class="k">as!</span> <span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Int32</span><span class="o">&gt;</span> <span class="p">}</span>
    <span class="k">let</span> <span class="nv">batchLength</span> <span class="o">=</span> <span class="n">tensorGPU</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dimensions</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">let</span> <span class="nv">output</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="nf">withStream</span><span class="p">(</span><span class="n">computeStream</span><span class="p">)</span> <span class="p">{</span> <span class="p">()</span> <span class="o">-&gt;</span> <span class="kt">Group</span><span class="o">&lt;</span><span class="kt">DynamicGraph</span><span class="o">.</span><span class="kt">AnyTensor</span><span class="o">&gt;</span> <span class="k">in</span>
      <span class="k">let</span> <span class="nv">wordIndices</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="nf">variable</span><span class="p">(</span><span class="n">tensorGPU</span><span class="o">.</span><span class="nf">reshaped</span><span class="p">(</span><span class="o">.</span><span class="kt">C</span><span class="p">(</span><span class="n">batchSize</span> <span class="o">*</span> <span class="n">batchLength</span><span class="p">)))</span>
      <span class="k">let</span> <span class="nv">wordVec</span> <span class="o">=</span> <span class="kt">Functional</span><span class="o">.</span><span class="nf">indexSelect</span><span class="p">(</span><span class="nv">input</span><span class="p">:</span> <span class="n">vocabVec</span><span class="p">,</span> <span class="nv">index</span><span class="p">:</span> <span class="n">wordIndices</span><span class="p">)</span>
      <span class="k">var</span> <span class="nv">seqIndicesCPU</span> <span class="o">=</span> <span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Int32</span><span class="o">&gt;</span><span class="p">(</span><span class="o">.</span><span class="kt">CPU</span><span class="p">,</span> <span class="o">.</span><span class="kt">C</span><span class="p">(</span><span class="n">batchSize</span> <span class="o">*</span> <span class="n">batchLength</span><span class="p">))</span>
      <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..&lt;</span><span class="n">batchSize</span> <span class="p">{</span>
        <span class="k">for</span> <span class="n">j</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..&lt;</span><span class="n">batchLength</span> <span class="p">{</span>
          <span class="n">seqIndicesCPU</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">batchLength</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="kt">Int32</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
        <span class="p">}</span>
      <span class="p">}</span>
      <span class="k">let</span> <span class="nv">seqIndicesGPU</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="o">..&lt;</span><span class="n">deviceCount</span><span class="p">)</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">seqIndicesCPU</span><span class="o">.</span><span class="nf">toGPU</span><span class="p">(</span><span class="nv">$0</span><span class="p">)</span> <span class="p">}</span>
      <span class="k">let</span> <span class="nv">seqIndices</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="nf">constant</span><span class="p">(</span><span class="n">seqIndicesGPU</span><span class="p">)</span>
      <span class="k">let</span> <span class="nv">posVec</span> <span class="o">=</span> <span class="kt">Functional</span><span class="o">.</span><span class="nf">indexSelect</span><span class="p">(</span><span class="nv">input</span><span class="p">:</span> <span class="n">seqVec</span><span class="p">,</span> <span class="nv">index</span><span class="p">:</span> <span class="n">seqIndices</span><span class="p">)</span>
      <span class="k">let</span> <span class="nv">selectVec</span> <span class="o">=</span> <span class="n">wordVec</span> <span class="o">+</span> <span class="n">posVec</span>
      <span class="k">let</span> <span class="nv">inputVec</span> <span class="o">=</span> <span class="n">selectVec</span><span class="o">.</span><span class="nf">reshaped</span><span class="p">(</span><span class="o">.</span><span class="kt">CHW</span><span class="p">(</span><span class="n">batchSize</span><span class="p">,</span> <span class="n">batchLength</span><span class="p">,</span> <span class="n">embeddingSize</span><span class="p">))</span>
      <span class="k">let</span> <span class="nv">masked</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="nf">constant</span><span class="p">(</span><span class="n">squaredMaskGPU</span><span class="o">.</span><span class="nf">reshaped</span><span class="p">(</span><span class="o">.</span><span class="kt">CHW</span><span class="p">(</span><span class="n">batchSize</span><span class="p">,</span> <span class="n">batchLength</span><span class="p">,</span> <span class="n">batchLength</span><span class="p">)))</span>
      <span class="k">let</span> <span class="nv">output</span> <span class="o">=</span> <span class="nf">transformer</span><span class="p">(</span><span class="nv">inputs</span><span class="p">:</span> <span class="n">inputVec</span><span class="p">,</span> <span class="n">masked</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
      <span class="k">let</span> <span class="nv">softmaxLoss</span> <span class="o">=</span> <span class="kt">SoftmaxCrossEntropyLoss</span><span class="p">()</span>
      <span class="k">let</span> <span class="nv">target</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="nf">variable</span><span class="p">(</span><span class="n">oneHotGPU</span><span class="p">)</span>
      <span class="k">let</span> <span class="nv">loss</span> <span class="o">=</span> <span class="nf">softmaxLoss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nv">target</span><span class="p">:</span> <span class="n">target</span><span class="p">)</span>
      <span class="n">loss</span><span class="o">.</span><span class="nf">backward</span><span class="p">(</span><span class="nv">to</span><span class="p">:</span> <span class="p">[</span><span class="n">vocabVec</span><span class="p">,</span> <span class="n">seqVec</span><span class="p">])</span>
      <span class="n">adamOptimizer</span><span class="o">.</span><span class="nf">step</span><span class="p">()</span>
      <span class="k">return</span> <span class="n">output</span>
    <span class="p">}</span>
    <span class="n">computeStream</span><span class="o">.</span><span class="nf">joined</span><span class="p">()</span>
    <span class="k">var</span> <span class="nv">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">k</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..&lt;</span><span class="n">deviceCount</span> <span class="p">{</span>
      <span class="k">let</span> <span class="nv">oneHot</span> <span class="o">=</span> <span class="n">oneHotGPU</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="nf">toCPU</span><span class="p">()</span>
      <span class="k">let</span> <span class="nv">output</span> <span class="o">=</span> <span class="kt">DynamicGraph</span><span class="o">.</span><span class="kt">Tensor</span><span class="o">&lt;</span><span class="kt">Float32</span><span class="o">&gt;</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">.</span><span class="nf">toCPU</span><span class="p">()</span>
      <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..&lt;</span><span class="n">batchSize</span> <span class="p">{</span>
        <span class="k">let</span> <span class="nv">truth</span> <span class="o">=</span> <span class="n">oneHot</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">oneHot</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">let</span> <span class="nv">prediction</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">truth</span> <span class="o">==</span> <span class="n">prediction</span> <span class="p">{</span>
          <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">let</span> <span class="nv">accuracy</span> <span class="o">=</span> <span class="kt">Double</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span> <span class="o">/</span> <span class="kt">Double</span><span class="p">(</span><span class="n">batchSize</span> <span class="o">*</span> <span class="n">deviceCount</span><span class="p">)</span>
    <span class="n">overallAccuracy</span> <span class="o">=</span> <span class="n">overallAccuracy</span> <span class="o">*</span> <span class="mf">0.9</span> <span class="o">+</span> <span class="n">accuracy</span> <span class="o">*</span> <span class="mf">0.1</span>
    <span class="k">if</span> <span class="n">adamOptimizer</span><span class="o">.</span><span class="n">step</span> <span class="o">%</span> <span class="mi">50</span>  <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
      <span class="nf">print</span><span class="p">(</span><span class="s">"epoch </span><span class="se">\(</span><span class="n">epoch</span><span class="se">)</span><span class="s"> (</span><span class="se">\(</span><span class="n">i</span><span class="se">)</span><span class="s">/</span><span class="se">\(</span><span class="n">batchedTrainData</span><span class="o">.</span><span class="n">count</span><span class="se">)</span><span class="s">), training accuracy </span><span class="se">\(</span><span class="n">overallAccuracy</span><span class="se">)</span><span class="s">"</span><span class="p">)</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre>

          </section>
        </section>
        <section id="footer">
          <p>&copy; 2022 <a class="link" href="" target="_blank" rel="external"></a>. All rights reserved. (Last updated: 2022-05-03)</p>
          <p>Generated by <a class="link" href="https://github.com/realm/jazzy" target="_blank" rel="external">jazzy ♪♫ v0.13.6</a>, a <a class="link" href="https://realm.io" target="_blank" rel="external">Realm</a> project.</p>
        </section>
      </article>
    </div>
  </body>
</div>
</html>
