

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Overview &mdash; nnc, a deep learning framework from ccv</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex/" />
    <link rel="search" title="Search" href="../search/" />
    <link rel="next" title="Technicals" href="../tech/" />
    <link rel="prev" title="NNC: Neural Network Collection" href="../" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../">
          

          
            
            <img src="../_static/nnc-logo.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                a deep learning framework from ccv
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#what-s-nnc">What’s NNC?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tensors-commands-and-streams">1. Tensors, Commands and Streams</a></li>
<li class="toctree-l2"><a class="reference internal" href="#computation-graph">2. Computation Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="#symbolic-graph">3. Symbolic Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dynamic-graph">4. Dynamic Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="#common-neural-network-primitives">5. Common Neural Network Primitives</a></li>
<li class="toctree-l2"><a class="reference internal" href="#supplementary-materials">Supplementary Materials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#toll-free-bridging">Toll-Free Bridging</a></li>
<li class="toctree-l3"><a class="reference internal" href="#automatic-differentiation">Automatic Differentiation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#while-type-sub-graph"><code class="docutils literal notranslate"><span class="pre">while</span></code> Type Sub-Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="#case-of-type-sub-graph"><code class="docutils literal notranslate"><span class="pre">case..of</span></code> Type Sub-Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="#limits-and-constraints">Limits and Constraints</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tech/">Technicals</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../tech/nnc-alloc/">The NNC Tensor Allocation Algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-alloc/#tensor-representation">Tensor Representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-alloc/#loop-representation">Loop Representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-alloc/#the-problem-definition">The Problem Definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-alloc/#the-core-algorithm">The Core Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-alloc/#basic-structure">Basic Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-alloc/#candidate-selection">Candidate Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-alloc/#insertion">Insertion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-alloc/#intuition">Intuition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-alloc/#loop">Loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-alloc/#multi-view-tensor">Multi-view Tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-alloc/#loop-with-efficient-tensor-allocation">Loop with Efficient Tensor Allocation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-alloc/#sub-computation-graph">Sub-Computation Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-alloc/#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tech/nnc-schd/">NNC Static Schedule A Graph</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-schd/#stream">Stream</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-schd/#static-schedule">Static Schedule</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-schd/#while-and-case-of"><code class="docutils literal notranslate"><span class="pre">while</span></code> and <code class="docutils literal notranslate"><span class="pre">case..of</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tech/nnc-dy/">NNC Dynamic Graph Execution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-dy/#naming-the-variable">Naming The Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-dy/#tracing-the-operation">Tracing The Operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-dy/#optimizations">Optimizations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-dy/#interoperability-not-ready">Interoperability (Not Ready)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-dy/#future-optimizations">Future Optimizations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-dy/#some-maybes">Some Maybes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tech/nnc-cnnp/">NNC Common Neural Network Primitives</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../tech/nnc-cnnp/#model">Model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/level-0/">Level 0 API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/level-0/#essentials">Essentials</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/level-1/">Level 1 API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/level-1/#tensors">Tensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level-1/#commands">Commands</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level-1/#streams">Streams</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/level-2/">Level 2 API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/level-2/#essentials">Essentials</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level-2/#others">Others</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/level-3/">Level 3 API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/level-3/#essentials">Essentials</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level-3/#others">Others</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/level-3.5/">Level 3.5 API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/level_3_5/group__level__3__5__case__of_symbolic_switch/">Construct “switch” control structure in symbolic graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level_3_5/group__level__3__5__simplify_symbolic_simplify/">Symbolic graph simplification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level_3_5/group__level__3__5__while_symbolic_while/">Construct a “while” loop in a symbolic graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level-3.5/#automatic-differentiation">Automatic Differentiation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level-3.5/#while-loop-essentials">While Loop Essentials</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level-3.5/#branching">Branching</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level-3.5/#gradient-based-optimization">Gradient-based Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level-3.5/#graph-simplification">Graph Simplification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level-3.5/#automatic-graph-parallelization">Automatic Graph Parallelization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level-3.5/#while-loop-others">While Loop Others</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/level-4/">Level 4 API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/level-4/#essentials">Essentials</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/level-5/">Level 5 API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/level_5/group__level__5_dataframe/">Dataframe</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level_5/group__level__5_model/">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/level-5/#essentials">Essentials</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/convenience/">Convenience API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/commands/">Available Commands</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/commands/#backends">Backends</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/commands/#commands">Commands</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/commands/#command-identifiers">Command Identifiers</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          
            <a href="../">
          

          
            
            <img src="../_static/nnc-logo.svg" class="logo" alt="Logo"/>
          
          </a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../">Docs</a> &raquo;</li>
        
      <li>Overview</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/overview.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h1>
<div class="section" id="what-s-nnc">
<h2>What’s NNC?<a class="headerlink" href="#what-s-nnc" title="Permalink to this headline">¶</a></h2>
<p>NNC is the natural progression against <code class="docutils literal notranslate"><span class="pre">ccv_convnet</span></code>, which is a couple of years old now. <code class="docutils literal notranslate"><span class="pre">ccv_convnet</span></code>’s monolithic, single path neural layer design didn’t really feel right with more advanced network architectures.</p>
<p>NNC took some good ideas from more recent neural network frameworks and did a long re-think on how to achieve both efficiency and expressiveness. The design itself is layered. At the highest layer, you have ordinary neural network primitives that reflect real-world usage such as Inception module, LSTM, RNN et al. At the lowest layer, depending on the infrastructure, it maps to allocated tensors on GPU, computations backed by CuDNN, and computation graphs driven with CUDA streams (or you can exchange that with CPU, Metal, and libdispatch). For the abstractions in between, there are trade-offs and constraints to accommodating both the library design and usage.</p>
<p>In a few sentences, here is how the layered design works.</p>
<p>NNC starts with tensors, commands and streams, which closely map to low level computation primitives. On top of that, a concrete computation graph can be constructed and executed directly. Above that, a symbolic graph can express everything about the concrete computation graph, without actual tensor and stream allocations. A dynamic graph can contain both symbolic graph representation and the concrete computation graph, thus, carries out the computation immediately while retain the ability to do series of processes on top of the symbolic graph representation. Familiar primitives such as LSTM or RNN then were built on top of either the symbolic graph or the dynamic graph constructs.</p>
<p>There are roughly <strong>5 layers</strong> built on top of each other.</p>
</div>
<div class="section" id="tensors-commands-and-streams">
<h2>1. Tensors, Commands and Streams<a class="headerlink" href="#tensors-commands-and-streams" title="Permalink to this headline">¶</a></h2>
<p>Tensors are multi-dimensional arrays at its basic level.</p>
<p>Commands are ops (operations) in other framework’s terminology.</p>
<p>Streams are the synchronization mechanism. Each command instance executed serially on a given stream. Different command instances on different streams will be scheduled in parallel if the underlying infrastructure permits.</p>
<p>A command is identified by its <code class="docutils literal notranslate"><span class="pre">cmd</span></code> identifier. It processes a set of input tensors, and write output to a set of output tensors. There is no limits on how many input tensors it can accept or how many output tensors it can write to.</p>
<p>A command can only have one set of attributes (recognized by NNC) specified. These attributes (such as whether this can be an <em>inplace</em> operation) help on symbolic processes. If you find that you need to implement the same command but these attributes cannot be hold, you need to rename the command to avoid invalid symbolic processes.</p>
<p>One command, however, can be backed by several <strong>backend</strong> implementations. Command backend implementors, besides the ones who implement <code class="docutils literal notranslate"><span class="pre">*_REF</span></code> free to only support specific cases of the input tensors (for example, a particular tensor layout, or a specific tensor size (3x3?), or half precision numbers). But once a backend accepts the input, it follows exactly the command attributes specified above (for example, any backend that implements a <em>inplace</em> command, will allow any parts of its input to be overwritten by this command at time while this command is executing without affecting the correctness of the output).</p>
<p>At runtime, a command will select the appropriate backend based on the input type and execution time.</p>
</div>
<div class="section" id="computation-graph">
<h2>2. Computation Graph<a class="headerlink" href="#computation-graph" title="Permalink to this headline">¶</a></h2>
<p><strong>Computation graph</strong> expresses how the computation carries out. The output tensors can be used as input for the next command, so on and so forth. That is where <em>TensorFlow</em> got its name from. At this layer, <strong>computation graph</strong> knows the execution orders (data dependencies) between each command instances, and will schedule them on proper streams to ensure these execution orders are respected. Tensors themselves are not associated with the execution order at this point.</p>
<p>A <strong>computation graph</strong> can contain a sub-graph, which is a <strong>computation graph</strong> itself. It is executed as a single command instance by the parent <strong>computation graph</strong>. As of now, a <em>``while`` type sub-graph</em> (for looping) and a <em>``case..of`` type sub-graph</em> (for branching) are supported.</p>
<p>A <strong>computation graph</strong> can be auto-tuned to find the best backend implementations that minimize the total execution time. There may be future optimizations to allow modifying the graph itself to do more aggressive tuning (such as including tensor conversions to trade between slower implementation and conversion + faster implementation).</p>
<p>In short, once you have a <strong>computation graph</strong>, the computation can be carried out naturally because there is no extra assumptions about execution environment and no more parameters or allocations need to be specified.</p>
</div>
<div class="section" id="symbolic-graph">
<h2>3. Symbolic Graph<a class="headerlink" href="#symbolic-graph" title="Permalink to this headline">¶</a></h2>
<p><strong>Symbolic graph</strong> expresses commands, the associated tensors and their execution orders (dependencies). This may sound very similar to the <strong>computation graph</strong> above, but there are several important differences:</p>
<ol class="arabic simple">
<li>there is no concept of <em>stream</em> at this point, because the <strong>symbolic graph</strong> doesn’t carry out the actual computation, and <em>stream</em> can be determined purely by the execution order;</li>
<li>there is no tensor allocation. <strong>Symbolic graph</strong> uses the tensor metadata (layout, precision, dimensions, even which GPU it is associated with), but no actual allocation took place until it is compiled to a <strong>computation graph</strong>;</li>
<li>There is no 1:1 mapping guarantee about the commands in the <strong>symbolic graph</strong> with the command instances in the <strong>computation graph</strong>.</li>
</ol>
<p>In fact, <strong>symbolic graph</strong> doesn’t take tensors. It takes tensor symbols. The tensor symbol usage within the symbolic graph follows strict <em>static single assignment (SSA)</em> rule. It can only be used as a command instance’s output once. This is important because by following <em>SSA</em>, potential data races are completely eliminated. More over, certain processes and the actual tensor allocation algorithm are much easier to implement with this assumption. With <em>SSA</em> rule, the execution orders (dependencies) can be generated trivially.</p>
<p>It may feel like the tensor metadata is over-specified. For example, why precision or layout, or which GPU it resides is relevant? Because tensor symbols have many to 1 mapping with the actual tensors. Specifications on the tensor symbol avoid processes on the <strong>symbolic graph</strong> resulting a tensor symbol that needs to be backed with conversions. Any conversions on the <strong>symbolic graph</strong> has to be explicit command instances.</p>
<p>Having that in mind, however, you can take an <em>alias</em> of a tensor symbol, which is a sliced / reshaped tensor symbol from the original. It allows several operations to be zero effort on the actual <strong>computation graph</strong>. The <em>alias</em> itself still have to follow the same <em>SSA</em> rule, which means all the <em>aliases</em> and the original tensor symbol can only be written once (if two <em>aliases</em> as outputs point to non-overlapping parts of the original tensor, the written-once rule is not violated).</p>
<p>Processes can be carried out on the <strong>symbolic graph</strong> ranging from <em>automatic differentiation</em>, to <em>common sub-expression elimination</em> (CSE), or <em>operator fusion</em> (finer-grained set of commands be replaced by a combined command implementation).</p>
<p>When the actual computation is needed. A <strong>symbolic graph</strong> can be compiled to a <strong>computation graph</strong>. The compilation process can involve optimizations that previously already possible on the given <strong>computation graph</strong> (such as CSE). More importantly, this step performs additional optimization passes that will violate the <em>SSA</em> rule above. Currently, it will perform following processes that are not available as pure optimization passes:</p>
<ol class="arabic simple">
<li>In-place safe command instance will operate on the same tensor symbol inputs / outputs whenever possible (for example, <code class="docutils literal notranslate"><span class="pre">1.23</span> <span class="pre">*</span> <span class="pre">x</span> <span class="pre">=&gt;</span> <span class="pre">y</span></code> will be re-written to <code class="docutils literal notranslate"><span class="pre">1.23</span> <span class="pre">*</span> <span class="pre">x</span> <span class="pre">=&gt;</span> <span class="pre">x</span></code> if no other places use <code class="docutils literal notranslate"><span class="pre">x</span></code>);</li>
<li>Tensor allocation based on the liveness analysis for the tensor symbols. This step will generate the many to 1 mapping between tensor symbols with the actual tensors;</li>
<li>Emit implicit commands for tensor initialization. Certain tensor symbols need to be initialized before use (zero init for now), which is impossible to know when until tensor allocation was taken place. This is one reason why there is no 1:1 mapping between <strong>symbolic graph</strong> and <strong>computation graph</strong>.</li>
</ol>
<p>All above steps are carried out recursively for its <em>``while`` / ``case..of`` type sub-graphs</em> too.</p>
</div>
<div class="section" id="dynamic-graph">
<h2>4. Dynamic Graph<a class="headerlink" href="#dynamic-graph" title="Permalink to this headline">¶</a></h2>
<p><strong>Dynamic graph</strong> operates on concrete tensor instances. It took input tensors, executed a command on them, and took the outputs. From this perspective, it is very similar to the <strong>computation graph</strong>. The conceptual difference, is that the <strong>computation graph</strong> carries out execution from a specification, while <strong>dynamic graph</strong> forms a specification from the actual execution.</p>
<p>Thus, <strong>dynamic graph</strong> will construct a <strong>symbolic graph</strong> along its execution. It enables the <strong>dynamic graph</strong> to perform the same kind of sophisticated optimization passes and analysis once needed (such as <em>automatic differentiation</em>)</p>
<p>More over, <strong>dynamic graph</strong> implements a simple memorization mechanism. The tensors it uses will carry a hash, as well as a specific command. The output tensors can be retrieved from the cache by the generated hash if it is possible, to avoid repetitive computations.</p>
</div>
<div class="section" id="common-neural-network-primitives">
<h2>5. Common Neural Network Primitives<a class="headerlink" href="#common-neural-network-primitives" title="Permalink to this headline">¶</a></h2>
<p>A set of <strong>common neural network primitives</strong> for modeling as well as parameter updates is provided. The API looks very much like <strong>Sonnet</strong> or <strong>Keras</strong>. <strong>Common neural network primitives</strong> implemented these interfaces at a common language layer (C language). Thus, variety of host languages to implement a simple shim layer on top to enable these high-level APIs.</p>
</div>
<div class="section" id="supplementary-materials">
<h2>Supplementary Materials<a class="headerlink" href="#supplementary-materials" title="Permalink to this headline">¶</a></h2>
<div class="section" id="toll-free-bridging">
<h3>Toll-Free Bridging<a class="headerlink" href="#toll-free-bridging" title="Permalink to this headline">¶</a></h3>
<p><em>Toll-free bridging</em> here means that a <code class="docutils literal notranslate"><span class="pre">ccv_dense_matrix_t</span></code> struct, without any conversions at all, can be cast to a <code class="docutils literal notranslate"><span class="pre">ccv_nnc_tensor_t</span></code> struct and then used with nnc directly. The byte pattern is specifically arranged such that a 3 dimensional <code class="docutils literal notranslate"><span class="pre">ccv_nnc_tensor_t</span></code> can be cast back to <code class="docutils literal notranslate"><span class="pre">ccv_dense_matrix_t</span></code> vice versa. This allows seamless integration with the rest of image process primitives provided by ccv.</p>
</div>
<div class="section" id="automatic-differentiation">
<h3>Automatic Differentiation<a class="headerlink" href="#automatic-differentiation" title="Permalink to this headline">¶</a></h3>
<p><em>Automatic differentiation</em> supported by nnc is its reverse mode. The implementation is simple enough because we enforced <em>SSA</em> throughout the <strong>symbolic graph</strong>.</p>
<p>Each command need to implement its forward function, as well as its backward function. The backward function takes the input / output of the its forward function, as well as the gradients (matching the output tensors) as its input. It outputs the gradients with respect to the input (matching the input tensors of the forward function).</p>
<p>When doing <em>automatic differentiation</em>, from its <strong>symbolic graph</strong>, a backward command matching each forward command is created. The execution order (dependencies) is exactly reverse. <em>SSA</em> guarantees each tensor symbol is written once, that means the gradient w.r.t. that symbol needs to only be summed once as well.</p>
<p><em>alias</em> introduced some complexities to the implementation. Namely, because an alias can be used as input for follow-up commands, its reverse suggests different gradients w.r.t. different <em>aliases</em> required to be summed at certain point. That means these gradients need to be potentially zero init to avoid generating garbage results. This is done by inserting zero init tensor symbol property, which indicated an implicit zero init command will be injected at <strong>symbolic graph</strong> compilation time.</p>
<p>The specific implementation also means taking second order derivative isn’t possible with nnc at this point. It will be possible however in the future once the backward function can be specified by a set of forward functions and then we can do command substitution on the <strong>symbolic graph</strong>.</p>
</div>
<div class="section" id="while-type-sub-graph">
<h3><code class="docutils literal notranslate"><span class="pre">while</span></code> Type Sub-Graph<a class="headerlink" href="#while-type-sub-graph" title="Permalink to this headline">¶</a></h3>
<p>The <em>``while`` type sub-graph</em> is a special type of a <strong>symbolic graph</strong> or a <strong>computation graph</strong>. This is because it expresses a generic loop structure with custom evaluation function supplied.</p>
<p>The loop execution within a <em>``while`` type sub-graph</em> looks like this:</p>
<ol class="arabic simple">
<li>The sub-graph starts the execution from a set of source command instances;</li>
<li>It proceeds either serially or in parallel until all evaluation command instances executed. The subsequent command instances are on hold;</li>
<li>The evaluation function is called, and depends on the result, the execution within the sub-graph will either abort (break), or continue, until all the destination command instances executed and reached;</li>
<li>Once all destination command instances executed and reached, we will start from step 1. again.</li>
</ol>
<p>For <em>``while`` type symbolic sub-graph</em>, the obvious question would be how <em>SSA</em> rule plays out in the loop structure. We allow in the sub-graph to specify certain output tensor symbols carry over to the input tensor symbols in the next round, practically made these input tensor symbols parameters. The <em>compilation</em> step will handle this properly and allocate the input tensors at the same memory locations as the output tensors (there are <code class="docutils literal notranslate"><span class="pre">ccv_nnc_tensor_multiview_t</span></code> workaround if the condition cannot be satisfied).</p>
<p>When doing <em>automatic differentiation</em>, a <code class="docutils literal notranslate"><span class="pre">ccv_nnc_tensor_tape_t</span></code> need to be provided for the <em>``while`` type sub-graph</em> to record the outputs properly.</p>
</div>
<div class="section" id="case-of-type-sub-graph">
<h3><code class="docutils literal notranslate"><span class="pre">case..of</span></code> Type Sub-Graph<a class="headerlink" href="#case-of-type-sub-graph" title="Permalink to this headline">¶</a></h3>
<p>The <em>``case..of`` type sub-graph</em> is another special type of a <strong>symbolic graph</strong> or a <strong>computation graph</strong>. It expresses a generic branch structure with custom evaluation function supplied.</p>
<p>The <em>``case..of`` type sub-graph</em> contains several separate sub-graphs identified by indexes from 0 to n:</p>
<ol class="arabic simple">
<li>The evaluation function is called, if the result is &gt;= 0, a sub-graph is selected for execution, otherwise, jump to step 3.;</li>
<li>The selected sub-graph executed from beginning to end;</li>
<li>If the result is &lt; 0, no sub-graph executed.</li>
</ol>
<p>For <em>``case..of`` type symbolic sub-graph</em>, if a tensor symbol is <em>written-once</em>, how to proceed if all sub-graphs skipped (in typical case, if a sub-graph executed, presumably, the tensor you want will be written by a command in that sub-graph)? We allow you to specify for these output tensor symbols, which symbol from the input can be supplied as <em>replacement</em>. The <em>compilation</em> step will ensure a <code class="docutils literal notranslate"><span class="pre">ccv_nnc_tensor_multiview_t</span></code> is created to handle these cases.</p>
<p>When doing <em>automatic differentiation</em>, a <code class="docutils literal notranslate"><span class="pre">ccv_nnc_tensor_tape_t</span></code> need to be provided for the <em>``case..of`` type sub-graph</em> to record the outputs properly.</p>
</div>
<div class="section" id="limits-and-constraints">
<h3>Limits and Constraints<a class="headerlink" href="#limits-and-constraints" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li>Tensor itself supports up to 8 dimensions. This is defined in <code class="docutils literal notranslate"><span class="pre">CCV_NNC_MAX_DIM_ALLOC</span></code>.</li>
<li>Tensor’s dimension can only reach to up <code class="docutils literal notranslate"><span class="pre">INT_MAX</span></code>. That may be a limiting factor for some of the tensors if they need more than 8GiB (32-bit floating point assumed) on one dimension.</li>
<li>The limit on number of inputs and output tensors is <code class="docutils literal notranslate"><span class="pre">INT_MAX</span></code>. To perform <em>automatic differentiation</em> properly, this number drops to <code class="docutils literal notranslate"><span class="pre">floor(INT_MAX</span> <span class="pre">/</span> <span class="pre">3)</span></code>. However, for more than 64 parameters, there are internal heap allocation required, which makes previously deterministic execution none-deterministic (it may take arbitrarily long depending on the <code class="docutils literal notranslate"><span class="pre">malloc</span></code> you use).</li>
<li>The allocated tensor size can go up to <code class="docutils literal notranslate"><span class="pre">min(UINT64_MAX,</span> <span class="pre">SIZE_MAX)</span></code>.</li>
<li>A computation can only depend on no more than <code class="docutils literal notranslate"><span class="pre">2^16</span></code> other computations. This is determined by a core macro <code class="docutils literal notranslate"><span class="pre">CCV_NNC_GRAPH_VISIT</span></code>.</li>
<li>The sub-graph can go as deep as <code class="docutils literal notranslate"><span class="pre">2^(31</span> <span class="pre">-</span> <span class="pre">4)</span></code>, otherwise the outer-most while count tensor cannot be referenced by the inner-most sub-graph.</li>
<li>The maximum number of GPU devices per machine or NUMA nodes per machine is 4095. This is defined in <code class="docutils literal notranslate"><span class="pre">CCV_COMPUTE_DEVICE_ANY</span></code>.</li>
</ol>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../tech/" class="btn btn-neutral float-right" title="Technicals" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../" class="btn btn-neutral" title="NNC: Neural Network Collection" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, libnnc.org.
      
        <span class="build">
          <a href="https://github.com/liuliu/ccv">View the project on GitHub</a>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'a deep learning framework from ccv',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  

  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-303081-9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-303081-9');
  </script>

   

</body>
</html>